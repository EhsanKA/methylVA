{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "107aba69-bd30-47a1-9b53-16249c57deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "# %reload_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d5981d6-f24c-4ae8-9a78-f2e158433672",
   "metadata": {},
   "outputs": [],
   "source": [
    "from methylVA.mnist.dataset import get_methyl_data_loaders\n",
    "\n",
    "data_id = 0.1\n",
    "batch_size = 128\n",
    "\n",
    "n_features = 2605\n",
    "n_samples_train = 33360\n",
    "n_samples_test = 3707\n",
    "\n",
    "train_data_path = f\"../data/random_data/train_data_{n_samples_train}_{n_features}.pkl\"\n",
    "test_data_path = f\"../data/random_data/test_data_{n_samples_test}_{n_features}.pkl\"\n",
    "\n",
    "train_metadata_path = f\"../data/random_data/train_metadata_{n_samples_train}_{n_features}.pkl\"\n",
    "test_metadata_path = f\"../data/random_data/test_metadata_{n_samples_test}_{n_features}.pkl\"\n",
    "\n",
    "\n",
    "train_loader, test_loader = get_methyl_data_loaders(\n",
    "    train_data_path,\n",
    "    train_metadata_path,\n",
    "    test_data_path,\n",
    "    test_metadata_path,\n",
    "    batch_size=batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f33efb-e026-47cf-8cee-2721346b2645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in each dataset: 2605\n",
      "Number of rows in the training dataset: 33360\n",
      "Number of rows in the test dataset: 3707\n"
     ]
    }
   ],
   "source": [
    "data_batch, _ = next(iter(train_loader))\n",
    "\n",
    "\n",
    "num_train_rows = len(train_loader.dataset)\n",
    "num_test_rows = len(test_loader.dataset)\n",
    "\n",
    "print(\"Number of features in each dataset:\", data_batch.shape[1])\n",
    "print(\"Number of rows in the training dataset:\", num_train_rows)\n",
    "print(\"Number of rows in the test dataset:\", num_test_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aa45a75-58d1-4fb4-b8d1-fea8e5526fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from methylVA.mnist.model import VAE\n",
    "from methylVA.mnist.training import train, test\n",
    "\n",
    "input_dim = data_batch.shape[1]\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-2\n",
    "num_epochs = 100\n",
    "latent_dim = 32\n",
    "hidden_dim = 2048\n",
    "kl_weight = 0.001\n",
    "name = f'VAE_random_data_{data_id}_latent_{latent_dim}_kl_{kl_weight}'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d8ebdb-af8a-4ce9-b093-b076fa10c2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1802a47b-3513-4890-a594-56f183ec54b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "writer_train = SummaryWriter(f'../experiments/{name}/train/{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')\n",
    "writer_test = SummaryWriter(f'../experiments/{name}/test/{datetime.now().strftime(\"%Y%m%d-%H%M%S\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb070f8-8e68-4809-81e6-febc696afaef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d605edb6-abee-4a41-8987-48adf90fc0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VAE(input_dim=input_dim, latent_dim=latent_dim, hidden_dim=hidden_dim).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9966ec03-4feb-473d-9d8f-de1702b45b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=2605, out_features=2048, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=2048, out_features=1024, bias=True)\n",
       "    (3): SiLU()\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): SiLU()\n",
       "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (7): SiLU()\n",
       "    (8): Linear(in_features=256, out_features=64, bias=True)\n",
       "  )\n",
       "  (softplus): Softplus(beta=1.0, threshold=20.0)\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=32, out_features=256, bias=True)\n",
       "    (1): SiLU()\n",
       "    (2): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (3): SiLU()\n",
       "    (4): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (5): SiLU()\n",
       "    (6): Linear(in_features=1024, out_features=2048, bias=True)\n",
       "    (7): SiLU()\n",
       "    (8): Linear(in_features=2048, out_features=2605, bias=True)\n",
       "    (9): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c20d498-f54b-4563-aed7-46061753bc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/261 [00:00<00:10, 24.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, (N samples: 0), Loss: 1809.3468, (Recon: 1805.6772, KLD: 3.6696), Gradient norm: 2.7886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 106/261 [00:03<00:04, 35.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 100, (N samples: 12,800), Loss: 1805.7599, (Recon: 1805.7499, KLD: 0.0101), Gradient norm: 1.6426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 206/261 [00:05<00:01, 35.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200, (N samples: 25,600), Loss: 1805.7383, (Recon: 1805.7368, KLD: 0.0014), Gradient norm: 1.6152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 261/261 [00:07<00:00, 34.84it/s]\n",
      "Testing: 100%|██████████| 29/29 [00:00<00:00, 41.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====> Test set loss: 1805.7304, (BCE: 1805.7290, KLD: 0.0015)\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 26/261 [00:00<00:07, 32.34it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     prev_updates \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_updates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     test(model, test_loader, prev_updates, writer\u001b[38;5;241m=\u001b[39mwriter_test)\n",
      "File \u001b[0;32m/fast/AG_Ohler/ekarimi/projects/methylVA/methylVA/mnist/training.py:18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, optimizer, prev_updates, batch_size, writer)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mTrains the model on the given data.\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    writer (SummaryWriter, optional): TensorBoard writer\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(dataloader)):\n\u001b[1;32m     19\u001b[0m     n_updates \u001b[38;5;241m=\u001b[39m prev_updates \u001b[38;5;241m+\u001b[39m batch_idx\n\u001b[1;32m     21\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(model\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/fast/AG_Ohler/ekarimi/miniforge/envs/meth/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/fast/AG_Ohler/ekarimi/miniforge/envs/meth/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/fast/AG_Ohler/ekarimi/miniforge/envs/meth/lib/python3.10/site-packages/torch/utils/data/dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/fast/AG_Ohler/ekarimi/miniforge/envs/meth/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/fast/AG_Ohler/ekarimi/miniforge/envs/meth/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/fast/AG_Ohler/ekarimi/projects/methylVA/methylVA/mnist/dataset.py:190\u001b[0m, in \u001b[0;36mMethylDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    188\u001b[0m sample \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39misnan(sample), \u001b[38;5;241m0.0\u001b[39m, sample)\n\u001b[1;32m    189\u001b[0m sample \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(sample, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m--> 190\u001b[0m sample \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mwhere(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m, torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m1.0\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32), sample)\n\u001b[1;32m    191\u001b[0m sample \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m    193\u001b[0m label \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from methylVA.mnist.training import train, test\n",
    "\n",
    "\n",
    "prev_updates = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs}')\n",
    "    prev_updates = train(model, train_loader, optimizer, prev_updates, writer=writer_train)\n",
    "    test(model, test_loader, prev_updates, writer=writer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f021808-1c7a-4056-8949-510ab6c38ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56c7168b-6332-47c0-bcf3-5af6a774aaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57f0fdc6-5053-47bc-bd46-d64b3e09aeb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6011 (pid 1110344), started 0:00:12 ago. (Use '!kill 1110344' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-63404df976634da8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-63404df976634da8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6011;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ../experiments/VAE_MNIST/20241028-004306/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc742882-f291-4e76-869c-8ad7999e29ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:meth]",
   "language": "python",
   "name": "conda-env-meth-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
